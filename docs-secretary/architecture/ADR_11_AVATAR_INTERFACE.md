# ADR-11: Conversational Avatar Interface

**Status:** ğŸŸ¡ Diskussion
**Datum:** 2026-02-15
**Kontext:** Integration eines realistischen Avatar-Interfaces fÃ¼r OpenClaw Bot

---

## Problem Statement

**Anforderung:** Ein realistischer, sprechender Avatar als Frontend-Interface, der:

- Mit Nutzern per Sprache kommuniziert (Voice-to-Voice)
- NatÃ¼rliche Lippensynchronisation hat
- Eigenes LLM-Backend nutzt (OpenClaw Agent)
- MÃ¶glichst realistische visuelle Darstellung
- In Echtzeit reagiert (<500ms Latenz)

**Use Cases:**

- PersÃ¶nlicher Assistent mit menschlichem Gesicht
- Video-Call-Ã¤hnliche Interaktion
- Alternative zu Text-basierten Messaging-Channels
- ErhÃ¶hte Engagement durch visuelles Feedback

---

## Technische Anforderungen

### Funktional

- **Voice Input:** Speech-to-Text (STT) Echtzeit
- **LLM Processing:** Integration mit OpenClaw Agent
- **Voice Output:** Text-to-Speech (TTS) mit Emotion
- **Avatar Animation:** Lippensync + GesichtsausdrÃ¼cke
- **Video Streaming:** WebRTC oder Ã¤hnlich

### Non-Funktional

- **Latenz:** End-to-End <2s (Speech Input â†’ Avatar Response)
- **Quality:** Mindestens 720p Video, 48kHz Audio
- **Ressourcen:** Sollte auf Consumer-Hardware laufen (oder Cloud)
- **Skalierung:** 1-10 concurrent Sessions

---

## Alternative A: LivePortrait + XTTS (Open Source, Echtzeit)

### Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Browser/Client                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Microphone â”‚â†’ â”‚ WebRTC Audio â”‚â†’ â”‚ Video Player    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚             â”‚                 â”‚
             â–¼             â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ STT Serviceâ”‚  â”‚  WebSocket   â”‚  â”‚Video Stream â”‚
    â”‚  (Whisper) â”‚  â”‚   Gateway    â”‚  â”‚   Server    â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                  â”‚
          â–¼                â–¼                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚         OpenClaw Agent Runtime                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ LLM Backend  â”‚  â”‚  Context Manager   â”‚    â”‚
    â”‚  â”‚ (Claude/GPT) â”‚  â”‚                    â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Avatar Generation Pipeline              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”â”‚
    â”‚  â”‚   TTS    â”‚â†’ â”‚ LivePortrait â”‚â†’ â”‚Video â”‚â”‚
    â”‚  â”‚  (XTTS)  â”‚  â”‚  Animation   â”‚  â”‚Encodeâ”‚â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack-Details

**1. Speech-to-Text: Whisper (OpenAI)**

```python
import whisper

model = whisper.load_model("base.en")  # oder "medium" fÃ¼r bessere QualitÃ¤t

async def transcribe_audio_stream(audio_chunk: bytes) -> str:
    result = model.transcribe(
        audio_chunk,
        language="de",  # oder "en"
        fp16=False  # CPU-kompatibel
    )
    return result["text"]
```

**2. Text-to-Speech: XTTS v2 (Coqui)**

```python
from TTS.api import TTS

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

async def generate_speech(text: str, reference_audio: str) -> bytes:
    # Voice cloning mit Referenz-Audio
    wav = tts.tts(
        text=text,
        speaker_wav=reference_audio,
        language="de"
    )
    return wav  # Audio bytes
```

**3. Avatar Animation: LivePortrait**

```python
from liveportrait import LivePortrait

animator = LivePortrait(
    model_path="checkpoints/liveportrait",
    device="cuda"  # oder "cpu"
)

async def animate_avatar(
    source_image: str,  # Statisches Portraitfoto
    driving_audio: bytes  # TTS-generiertes Audio
) -> bytes:
    video_frames = animator.animate(
        source_image=source_image,
        audio=driving_audio,
        fps=25
    )
    return encode_video(video_frames)  # MP4 oder WebM
```

**4. Integration in OpenClaw**

```typescript
// Neuer Channel: "avatar"
class AvatarChannel implements Channel {
  private whisper: WhisperSTT;
  private xtts: XTTSSTT;
  private livePortrait: LivePortraitAnimator;

  async handleIncomingAudio(audioStream: ReadableStream) {
    // 1. STT
    const text = await this.whisper.transcribe(audioStream);

    // 2. Send to Agent (wie WhatsApp/Telegram)
    const response = await this.sendToAgent({
      sessionId: this.sessionId,
      channel: "avatar",
      content: { type: "text", text },
    });

    // 3. TTS
    const audioResponse = await this.xtts.synthesize(response.content.text, this.userVoiceProfile);

    // 4. Avatar Animation
    const videoStream = await this.livePortrait.animate(this.avatarImage, audioResponse);

    // 5. Stream zurÃ¼ck zu Client
    return videoStream;
  }
}
```

### Vorteile

- âœ… **VollstÃ¤ndige Kontrolle** Ã¼ber alle Komponenten
- âœ… **Open Source** - keine Vendor Lock-in
- âœ… **On-Premise** mÃ¶glich - keine Cloud-AbhÃ¤ngigkeit
- âœ… **Customization** - eigene Modelle, eigene Avatare
- âœ… **Kosteneffizient** - nur GPU/CPU Kosten, keine API-GebÃ¼hren
- âœ… **Privacy** - alle Daten bleiben lokal

### Nachteile

- âŒ **Hardware-Anforderungen** - braucht GPU (min. RTX 3060) fÃ¼r Echtzeit
- âŒ **Setup-KomplexitÃ¤t** - mehrere ML-Modelle orchestrieren
- âŒ **QualitÃ¤t** - nicht ganz so gut wie kommerzielle LÃ¶sungen
- âŒ **Latenz** - 1-3s fÃ¼r komplette Pipeline (akzeptabel)
- âŒ **Wartungsaufwand** - Modell-Updates, Bug-Fixes

### Hardware-Anforderungen

- **CPU:** 8+ Cores (fÃ¼r Whisper + Backend)
- **GPU:** NVIDIA RTX 3060+ (12GB VRAM) fÃ¼r Echtzeit-Animation
- **RAM:** 16GB+
- **Storage:** 20GB fÃ¼r Modelle

### GeschÃ¤tzte Latenz (RTX 4090)

| Pipeline-Schritt         | Latenz                |
| ------------------------ | --------------------- |
| STT (Whisper base)       | ~200ms (pro 3s Audio) |
| LLM (Claude API)         | 500-2000ms            |
| TTS (XTTS)               | ~500ms (pro Satz)     |
| Animation (LivePortrait) | ~300ms (fÃ¼r 3s Video) |
| **Total**                | **~1.5-3s**           |

### Kosten

- **Entwicklung:** ğŸŸ¡ Mittel (2-3 Wochen)
- **Hardware (einmalig):** â‚¬1,500-3,000 (GPU-Server)
- **Betrieb:** â‚¬0 (auÃŸer Strom) + LLM API Kosten

---

## Alternative B: D-ID API (Kommerziell, Plug & Play)

### Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚
â”‚ (D-ID SDK)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ WebRTC
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D-ID Streaming  â”‚  â† Managed Service
â”‚      API         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Webhook/WebSocket
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenClaw Gateway   â”‚
â”‚  (Custom Backend)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenClaw Agent  â”‚
â”‚  (Dein LLM)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Integration

```typescript
import { DIDClient } from "@d-id/client-sdk";

class DIDIntegration {
  private didClient: DIDClient;

  async startConversation(avatarImageUrl: string) {
    // 1. Create D-ID Stream
    const stream = await this.didClient.streams.create({
      source_url: avatarImageUrl,
      stream_warmup: true,
    });

    // 2. Connect WebSocket fÃ¼r Bidirektionale Kommunikation
    const ws = new WebSocket(stream.session_url);

    ws.on("user_speech", async (text: string) => {
      // 3. Send to OpenClaw
      const response = await this.sendToAgent({
        channel: "did-avatar",
        content: { type: "text", text },
      });

      // 4. Send back to D-ID fÃ¼r Animation
      ws.send({
        type: "speak",
        text: response.content.text,
      });
    });
  }
}
```

### Vorteile

- âœ… **Beste QualitÃ¤t** - State-of-the-Art Animation
- âœ… **Einfachste Integration** - SDK + API
- âœ… **Niedrige Latenz** - <1s in guten Netzwerken
- âœ… **Keine Hardware** - lÃ¤uft in Cloud
- âœ… **Schnelle Time-to-Market** - <1 Woche Integration

### Nachteile

- âŒ **Kosten:** $0.20-0.50 pro Minute (kann teuer werden)
- âŒ **Vendor Lock-in** - abhÃ¤ngig von D-ID
- âŒ **Privacy Concerns** - Audio/Video geht durch D-ID Server
- âŒ **Limited Customization** - kann nicht alles anpassen
- âŒ **Netzwerk-AbhÃ¤ngigkeit** - braucht stabile Verbindung

### Kosten

| Nutzung     | Monatliche Kosten |
| ----------- | ----------------- |
| 10h/Monat   | ~$120-300         |
| 100h/Monat  | ~$1,200-3,000     |
| 1000h/Monat | ~$12,000-30,000   |

### GeschÃ¤tzte Latenz

- **End-to-End:** 800ms-1.5s (optimiert)

---

## Alternative C: Hybrid - HeyGen + Custom LLM Backend

### Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HeyGen Streaming API   â”‚ â† Managed (Video + TTS)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Real-time Event Stream
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Middleware/Orchestrator â”‚
â”‚   (WebSocket Proxy)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenClaw Agent        â”‚
â”‚   (Custom LLM)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Integration Pattern

```typescript
class HeyGenOrchestrator {
  async streamConversation(sessionId: string) {
    // 1. Start HeyGen Stream
    const heygenStream = await heygenClient.streaming.start({
      avatar_id: "custom-avatar-id",
      voice_id: "custom-voice-id",
    });

    // 2. Bidirectional Proxy
    const userToAgent = heygenStream.on("user_transcript", async (text) => {
      const agentResponse = await openclawAgent.process({
        sessionId,
        input: text,
      });

      // Send back to HeyGen for rendering
      await heygenStream.task.repeat({
        text: agentResponse.text,
        task_type: "repeat",
      });
    });

    return heygenStream.sessionUrl;
  }
}
```

### Vorteile

- âœ… **Exzellente QualitÃ¤t** - HeyGen fÃ¼hrend in realistischer Animation
- âœ… **Custom LLM Backend** - volle Kontrolle Ã¼ber AI-Logik
- âœ… **Managed Video/TTS** - reduziert eigene Infrastruktur
- âœ… **Moderate Latenz** - ~1-2s

### Nachteile

- âŒ **HÃ¶here Kosten** - Ã¤hnlich wie D-ID
- âŒ **Partial Lock-in** - Video-Teil abhÃ¤ngig von HeyGen
- âŒ **KomplexitÃ¤t** - Orchestrierung zwischen HeyGen + OpenClaw

### Kosten

- Ã„hnlich wie D-ID: $0.15-0.40/Minute
- Plus: OpenClaw Betrieb + LLM API

---

## Alternative D: SadTalker + Offline (Budget-Variante)

### Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Upload Audio
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenClaw Gateway    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SadTalker Pipeline     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ TTS â”‚â†’ â”‚SadTalker â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ Rendered Video
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚
â”‚ (Video Play) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Charakteristik

- **Nicht-Echtzeit:** User sendet Frage â†’ wartet 5-10s â†’ bekommt Video
- **Offline:** Alles lokal, keine Cloud
- **GÃ¼nstig:** Nur GPU + Strom

### Vorteile

- âœ… **100% Privacy** - nichts verlÃ¤sst Server
- âœ… **Niedrige Kosten** - nur Hardware
- âœ… **Einfach** - weniger Moving Parts

### Nachteile

- âŒ **Keine Echtzeit** - 5-15s VerzÃ¶gerung
- âŒ **Schlechtere UX** - kein flieÃŸendes GesprÃ¤ch
- âŒ **Quality** - nicht so gut wie Alternativen A-C

---

## Vergleichsmatrix

| Kriterium        | Alternative A (LivePortrait) | Alternative B (D-ID) | Alternative C (HeyGen) | Alternative D (SadTalker) |
| ---------------- | ---------------------------- | -------------------- | ---------------------- | ------------------------- |
| **QualitÃ¤t**     | â­â­â­ Gut                   | â­â­â­â­â­ Exzellent | â­â­â­â­â­ Exzellent   | â­â­ OK                   |
| **Latenz**       | ğŸŸ¡ 1.5-3s                    | ğŸŸ¢ <1s               | ğŸŸ¡ 1-2s                | ğŸ”´ 5-15s                  |
| **Kosten/Monat** | ğŸ’° â‚¬50-150 (GPU)             | ğŸ’°ğŸ’°ğŸ’° â‚¬500-3000     | ğŸ’°ğŸ’°ğŸ’° â‚¬400-2500       | ğŸ’° â‚¬30-80                 |
| **Privacy**      | ğŸŸ¢ 100% lokal                | ğŸ”´ Cloud-basiert     | ğŸ”´ Cloud-basiert       | ğŸŸ¢ 100% lokal             |
| **Setup**        | ğŸŸ¡ Mittel                    | ğŸŸ¢ Einfach           | ğŸŸ¢ Einfach             | ğŸŸ¢ Einfach                |
| **Control**      | ğŸŸ¢ VollstÃ¤ndig               | ğŸ”´ Limited           | ğŸŸ¡ Partial             | ğŸŸ¢ VollstÃ¤ndig            |
| **Hardware**     | RTX 3060+                    | Keine                | Keine                  | RTX 2060+                 |
| **Echtzeit**     | âœ… Ja                        | âœ… Ja                | âœ… Ja                  | âŒ Nein                   |

---

## Integration in OpenClaw Architektur

### Modulare Integration (empfohlen)

```typescript
// Neue Komponente: AvatarService
interface AvatarService {
  startSession(config: AvatarConfig): Promise<AvatarSession>;
  processAudio(sessionId: string, audio: Buffer): Promise<VideoStream>;
  endSession(sessionId: string): Promise<void>;
}

// Implementation Variants
class LivePortraitAvatarService implements AvatarService {
  /* ... */
}
class DIDavatarService implements AvatarService {
  /* ... */
}
class HeyGenAvatarService implements AvatarService {
  /* ... */
}

// In OpenClaw Gateway
class Gateway {
  private avatarService: AvatarService;

  constructor(config: GatewayConfig) {
    // Factory Pattern - wÃ¤hle Implementation
    this.avatarService = AvatarServiceFactory.create(
      config.avatarProvider, // 'liveportrait' | 'did' | 'heygen'
    );
  }

  async handleAvatarChannel(message: InboundMessage) {
    // Einheitliche Schnittstelle, egal welche Implementation
    const videoResponse = await this.avatarService.processAudio(
      message.sessionId,
      message.audioData,
    );

    return videoResponse;
  }
}
```

### Bezug zu unseren ADRs

**ADR-01 (Architektur):**

- Avatar Service als **eigenstÃ¤ndiger Service** (Microservices)
- Oder als **Modul** im Monolithen
- â†’ Empfehlung: EigenstÃ¤ndig wegen GPU-Requirements

**ADR-05 (Message Broker):**

- Audio-Streaming via **WebRTC** (nicht Message Broker)
- LLM-Anfragen weiterhin via Broker
- â†’ Hybrid-Ansatz

**ADR-03 (Sandboxing):**

- Avatar-Service braucht **GPU-Zugriff** (keine Sandbox)
- Isoliert von Tool-Execution
- â†’ Eigener Pod/Container

---

## ğŸ—³ï¸ Empfehlung

### FÃ¼r MVP / Prototyping

**Alternative B (D-ID API)**

- Schnellste Time-to-Market (1 Woche)
- Minimales Risiko
- Beweise Use Case, bevor groÃŸe Investment

### FÃ¼r Production / Scale

**Alternative A (LivePortrait + XTTS)**

- Langfristig gÃ¼nstiger bei >50h/Monat Nutzung
- Volle Kontrolle und Privacy
- Skalierbar mit eigener Infra

### FÃ¼r Budget-Constrained

**Alternative D (SadTalker)**

- Funktioniert, aber UX leidet
- Gut fÃ¼r Demos, nicht fÃ¼r Production

### Hybrid-Strategie

1. **Phase 1 (Monat 1-2):** D-ID fÃ¼r MVP
2. **Phase 2 (Monat 3-6):** Parallel LivePortrait entwickeln
3. **Phase 3 (Monat 6+):** Migration zu LivePortrait wenn ROI positiv

---

## Implementierungs-Roadmap

### Quick Start (Alternative B - D-ID)

**Woche 1:**

- [ ] D-ID Account + API Keys
- [ ] Avatar erstellen (Custom Photo)
- [ ] SDK Integration in OpenClaw

**Woche 2:**

- [ ] WebSocket Proxy bauen
- [ ] OpenClaw Agent anbinden
- [ ] Testing + Finetuning

**Woche 3:**

- [ ] Frontend (React/Vue)
- [ ] Deployment
- [ ] User Testing

**Aufwand:** 3 Wochen, 1 Developer

### Full Stack (Alternative A - LivePortrait)

**Wochen 1-2:**

- [ ] Hardware Setup (GPU Server)
- [ ] Whisper Integration
- [ ] XTTS Integration

**Wochen 3-4:**

- [ ] LivePortrait Setup
- [ ] Pipeline Orchestrierung
- [ ] Latenz-Optimierung

**Wochen 5-6:**

- [ ] Frontend (WebRTC)
- [ ] OpenClaw Integration
- [ ] Testing

**Aufwand:** 6-8 Wochen, 2 Developers

---

## Offene Fragen

1. **Budget:** Wie viel â‚¬ pro Monat fÃ¼r Avatar-Service?
2. **Nutzung:** GeschÃ¤tzte Stunden/Monat?
3. **Privacy:** Ist Cloud-Processing akzeptabel?
4. **Hardware:** Hast du bereits GPU-Server?
5. **Timeline:** Wie schnell soll es live gehen?
6. **Sprache:** PrimÃ¤r Deutsch, Englisch, oder multilingual?

---

## NÃ¤chste Schritte

1. **Entscheidung:** Welche Alternative passt zu deinen Constraints?
2. **Proof-of-Concept:** 1-2 Wochen mit gewÃ¤hlter LÃ¶sung
3. **Integration Planning:** Wie fÃ¼gt sich in OpenClaw-Architecture ein?
4. **Resource Planning:** Hardware/API-Budget freigeben

**Was ist deine initiale PrÃ¤ferenz? Oder soll ich eine detaillierte Kosten-Nutzen-Analyse fÃ¼r deine spezifische Situation erstellen?**
